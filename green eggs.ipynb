{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sam I Am\n",
    "\n",
    "## Description\n",
    "\n",
    "Imagine you have a child who wants to know which character is talking in a story. What you can do is running the dialog through a model and see what it thinks. \n",
    "\n",
    "At some level this is sentiment analysis. Instead of pick a value you are pick whom is talking.\n",
    "\n",
    "The first step is generating the story, and this one is shamelessly lifted since it has a small vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['i', 'am', 'sam'], 1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "def storyAppend(line,who):\n",
    "    records.append([line.split(\" \"),who])\n",
    "\n",
    "storyAppend(\"i am sam\",1)\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storyAppend(\"sam I am\",1)\n",
    "storyAppend(\"I do not like that sam I am\",0)\n",
    "storyAppend(\"do you like green eggs and ham\",1)\n",
    "storyAppend(\"I do not like green eggs and ham\",0)\n",
    "storyAppend(\"would you eat them here or there\",1)\n",
    "storyAppend(\"I would not eath them anywhere\",0)\n",
    "storyAppend(\"would you eat them here or there\",1)\n",
    "storyAppend(\"I would not eat them anywhere\",0)\n",
    "storyAppend(\"would you eat them with a fox\",1)\n",
    "storyAppend(\"I would not eat them with a fox\",0)\n",
    "storyAppend(\"could you eat them in a box\",1)\n",
    "storyAppend(\"I could not eat them in a box I would not eat them with a fox I do not like green eggs and ham sam I am\",0)\n",
    "storyAppend(\"would you eat them with a goat\",1)\n",
    "storyAppend(\"I would not eat them with a goat\",0)\n",
    "storyAppend(\"could you eat them in a boat\",1)\n",
    "storyAppend(\"I could not eat them in a boat I would not eat them with a goat\",0)\n",
    "storyAppend(\"would you eat them in the rain\",1)\n",
    "storyAppend(\"I would not eat them in the rain\",0)\n",
    "storyAppend(\"could you eat them on a train\",1)\n",
    "storyAppend(\"I could not eat them in the rain I would not eat them on a train I do not like green eggs and ham sam I am\",0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is create an index for each of the words so we can look them up. Here we sort alphabetically since we are goint to use the vlookup function, but we really could have assigned anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \tI\t1\n",
      "2 \ta\t2\n",
      "3 \tam\t3\n",
      "4 \tand\t4\n",
      "5 \tanywhere\t5\n",
      "6 \tboat\t6\n",
      "7 \tbox\t7\n",
      "8 \tcould\t8\n",
      "9 \tdo\t9\n",
      "10 \teat\t10\n",
      "11 \teath\t11\n",
      "12 \teggs\t12\n",
      "13 \tfox\t13\n",
      "14 \tgoat\t14\n",
      "15 \tgreen\t15\n",
      "16 \tham\t16\n",
      "17 \there\t17\n",
      "18 \ti\t18\n",
      "19 \tin\t19\n",
      "20 \tlike\t20\n",
      "21 \tnot\t21\n",
      "22 \ton\t22\n",
      "23 \tor\t23\n",
      "24 \train\t24\n",
      "25 \tsam\t25\n",
      "26 \tthat\t26\n",
      "27 \tthe\t27\n",
      "28 \tthem\t28\n",
      "29 \tthere\t29\n",
      "30 \ttrain\t30\n",
      "31 \twith\t31\n",
      "32 \twould\t32\n"
     ]
    }
   ],
   "source": [
    "wordsToIndex = {}\n",
    "indexToWords = {}\n",
    "\n",
    "nextword = 1\n",
    "\n",
    "for rec in records:\n",
    "    text = rec[0]\n",
    "    for word in text:\n",
    "        wordsToIndex[word] = 1\n",
    "for word in sorted(wordsToIndex.keys()):\n",
    "    wordsToIndex[word] = nextword\n",
    "    indexToWords[nextword] = word\n",
    "    nextword += 1\n",
    "    \n",
    "for i in range(1, nextword -1):\n",
    "    word = indexToWords[i]\n",
    "    iWord = wordsToIndex[word]\n",
    "    print str(i) + \" \\t\" + word +\"\\t\" + str(iWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create sentences of the same size. This is going to have two parts.\n",
    "-  We want to find the average length and pad or the other sentences\n",
    "-  we want to convert the sentences to there corresponding indexes so we can do lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgcount = 0\n",
    "for rec in records:\n",
    "    text = rec[0]\n",
    "    avgcount += len(text)\n",
    "seq_len = int(avgcount/len(records))\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create mapping that go back and forth between the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20, 6, 0, 0, 0, 0, 0]\n",
      "I like boat\n"
     ]
    }
   ],
   "source": [
    "def wordListToIndexList(wordArray):\n",
    "    nums = []\n",
    "    for i in range(0,seq_len - 1):\n",
    "        num = 0\n",
    "        # do we need to pad\n",
    "        if i < len(wordArray):\n",
    "            num = wordsToIndex[wordArray[i]]\n",
    "        nums.append(num)\n",
    "    return nums\n",
    "\n",
    "def indexListToString(indexArray):\n",
    "    sentence = indexToWords[indexArray[0]]\n",
    "    for i in range(1,seq_len - 1):\n",
    "        wordIndex = indexArray[i]\n",
    "        if wordIndex in indexToWords:\n",
    "            sentence = sentence + \" \" + indexToWords[wordIndex]\n",
    "\n",
    "    return sentence\n",
    "\n",
    "testSentence = wordListToIndexList([\"I\", \"like\", \"boat\"])\n",
    "print(testSentence)\n",
    "print(indexListToString(testSentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\t3\t25\t0\t0\t0\t0\t0\t\t1\n",
      "25\t1\t3\t0\t0\t0\t0\t0\t\t1\n",
      "1\t9\t21\t20\t26\t25\t1\t3\t\t0\n",
      "9\t33\t20\t15\t12\t4\t16\t0\t\t1\n",
      "1\t9\t21\t20\t15\t12\t4\t16\t\t0\n",
      "32\t33\t10\t28\t17\t23\t29\t0\t\t1\n",
      "1\t32\t21\t11\t28\t5\t0\t0\t\t0\n",
      "32\t33\t10\t28\t17\t23\t29\t0\t\t1\n",
      "1\t32\t21\t10\t28\t5\t0\t0\t\t0\n",
      "32\t33\t10\t28\t31\t2\t13\t0\t\t1\n",
      "1\t32\t21\t10\t28\t31\t2\t13\t\t0\n",
      "8\t33\t10\t28\t19\t2\t7\t0\t\t1\n",
      "1\t8\t21\t10\t28\t19\t2\t7\t\t0\n",
      "32\t33\t10\t28\t31\t2\t14\t0\t\t1\n",
      "1\t32\t21\t10\t28\t31\t2\t14\t\t0\n",
      "8\t33\t10\t28\t19\t2\t6\t0\t\t1\n",
      "1\t8\t21\t10\t28\t19\t2\t6\t\t0\n",
      "32\t33\t10\t28\t19\t27\t24\t0\t\t1\n",
      "1\t32\t21\t10\t28\t19\t27\t24\t\t0\n",
      "8\t33\t10\t28\t22\t2\t30\t0\t\t1\n",
      "1\t8\t21\t10\t28\t19\t27\t24\t\t0\n"
     ]
    }
   ],
   "source": [
    "trimmedlines = []\n",
    "\n",
    "  \n",
    "for rec in records:\n",
    "    text = rec[0]\n",
    "    trimmedlines.append([wordListToIndexList(text),rec[1]])\n",
    "\n",
    "    #now print it\n",
    "    \n",
    "for rec in trimmedlines:\n",
    "    nums = rec[0]\n",
    "    base = str(nums[0])\n",
    "    for i in range(1,seq_len - 1):\n",
    "        base = base + \"\\t\" + str(nums[i])\n",
    "    print base +\"\\t\\t\" + str(rec[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now copy this to our excel spreadsheet and run from there but first we can check to see if it makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am sam\n",
      "sam I am\n",
      "I do not like that sam I am\n",
      "do you like green eggs and ham\n",
      "I do not like green eggs and ham\n",
      "would you eat them here or there\n",
      "I would not eath them anywhere\n",
      "would you eat them here or there\n",
      "I would not eat them anywhere\n",
      "would you eat them with a fox\n",
      "I would not eat them with a fox\n",
      "could you eat them in a box\n",
      "I could not eat them in a box\n",
      "would you eat them with a goat\n",
      "I would not eat them with a goat\n",
      "could you eat them in a boat\n",
      "I could not eat them in a boat\n",
      "would you eat them in the rain\n",
      "I would not eat them in the rain\n",
      "could you eat them on a train\n",
      "I could not eat them in the rain\n"
     ]
    }
   ],
   "source": [
    "for rec in trimmedlines:\n",
    "    nums = rec[0]\n",
    "\n",
    "    print(indexListToString(nums))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2 using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapped name None to device cuda: GeForce GTX 1080\n",
      "Using cuDNN version 5105 on context None\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 9\n"
     ]
    }
   ],
   "source": [
    "#lets check some of the parameters he used.\n",
    "vocab_size = len(trimmedlines)\n",
    "numFilters = 2\n",
    "denseSize = 5\n",
    "\n",
    "print(vocab_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    keras.layers.embeddings.Embedding(vocab_size, numFilters, input_length=seq_len),\n",
    "    Flatten(),\n",
    "    Dense(denseSize, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 9, 2)          42          embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18)            0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 5)             95          flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 5)             0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             6           dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 143\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn = []\n",
    "labels_train = []\n",
    "for rec in trimmedlines:\n",
    "    trn.append(rec[0])\n",
    "    labels_train.append(rec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "This is where I break. my model isn't in t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking model input: expected embedding_input_1 to have shape (None, 9) but got array with shape (21, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2d7cd665bde9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/arthur/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/arthur/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m                                                            batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arthur/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    977\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m    980\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m    981\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arthur/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m    109\u001b[0m                                         \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                                         \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                                         str(array.shape))\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking model input: expected embedding_input_1 to have shape (None, 9) but got array with shape (21, 8)"
     ]
    }
   ],
   "source": [
    "model.fit(trn, labels_train, validation_data=(trn, labels_train), nb_epoch=2, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
